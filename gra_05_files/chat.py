import shutil
import gradio as gr
from mysite.libs.utilities import chat_with_interpreter, completion, process_file
from interpreter import interpreter
import mysite.interpreter.interpreter_config  # ã‚¤ãƒ³ãƒãƒ¼ãƒˆã™ã‚‹ã ã‘ã§è¨­å®šãŒé©ç”¨ã•ã‚Œã¾ã™
import importlib
import os
import pkgutil
import async_timeout
import asyncio


DESCRIPTION = """
<div>
<h1 style="text-align: center;">develop site</h1>
<p>ğŸ¦• å…±åŒé–‹ç™º AIã‚·ã‚¹ãƒ†ãƒ è¨­å®š LINEé–‹ç™º CHATGPTS CHATGPTã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆè¨­å®š AIè‡ªå‹•é–‹ç™ºè¨­å®š APPSHEET GAS PYTHON</p>
</div>
<!-- Start of HubSpot Embed Code -->
  <script type="text/javascript" id="hs-script-loader" async defer src="//js-na1.hs-scripts.com/46277896.js"></script>
<!-- End of HubSpot Embed Code -->
"""

LICENSE = """
<p/>
<!-- Start of HubSpot Embed Code -->
  <script type="text/javascript" id="hs-script-loader" async defer src="//js-na1.hs-scripts.com/46277896.js"></script>
<!-- End of HubSpot Embed Code -->
---
Built with Meta Llama 3
"""

PLACEHOLDER = """
<div style="padding: 30px; text-align: center; display: flex; flex-direction: column; align-items: center;">
   <img src="https://ysharma-dummy-chat-app.hf.space/file=/tmp/gradio/8e75e61cc9bab22b7ce3dec85ab0e6db1da5d107/Meta_lockup_positive%20primary_RGB.jpg" style="width: 80%; max-width: 550px; height: auto; opacity: 0.55;  ">
   <h1 style="font-size: 28px; margin-bottom: 2px; opacity: 0.55;">Meta llama3</h1>
   <p style="font-size: 18px; margin-bottom: 2px; opacity: 0.65;">Ask me anything...</p>
</div>
"""


# ãƒãƒ£ãƒƒãƒˆã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ã®é–¢æ•°å®šç¾©
# def chat_with_interpreter(message):
#    return "Response: " + message


# ã‚«ã‚¹ã‚¿ãƒ CSSã®å®šç¾©
css = """
.gradio-container {
    height: 100vh; /* å…¨ä½“ã®é«˜ã•ã‚’100vhã«è¨­å®š */
    display: flex;
    flex-direction: column;
}
.gradio-tabs {
    flex: 1; /* ã‚¿ãƒ–å…¨ä½“ã®é«˜ã•ã‚’æœ€å¤§ã«è¨­å®š */
    display: flex;
    flex-direction: column;
}
.gradio-tab-item {
    flex: 1; /* å„ã‚¿ãƒ–ã®é«˜ã•ã‚’æœ€å¤§ã«è¨­å®š */
    display: flex;
    flex-direction: column;
    overflow: hidden; /* ã‚ªãƒ¼ãƒãƒ¼ãƒ•ãƒ­ãƒ¼ã‚’éš ã™ */
}
.gradio-block {
    flex: 1; /* ãƒ–ãƒ­ãƒƒã‚¯ã®é«˜ã•ã‚’æœ€å¤§ã«è¨­å®š */
    display: flex;
    flex-direction: column;
}
.gradio-chatbot {
    height: 100vh; /* ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆã®é«˜ã•ã‚’100vhã«è¨­å®š */
    overflow-y: auto; /* ç¸¦ã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«ã‚’æœ‰åŠ¹ã«ã™ã‚‹ */
}
"""
GENERATION_TIMEOUT_SEC = 60
# Gradio block
chatbot2 = gr.Chatbot(height=450, placeholder=PLACEHOLDER, label="Gradio ChatInterface")

with gr.Blocks(fill_height=True, css=css) as chat:
    # gr.Markdown(DESCRIPTION)
    # gr.DuplicateButton(value="Duplicate Space for private use", elem_id="duplicate-button")
    gr.ChatInterface(
        fn=completion,
        chatbot=chatbot2,
        fill_height=True,
        additional_inputs_accordion=gr.Accordion(
            label="âš™ï¸ Parameters", open=False, render=False
        ),
        additional_inputs=[
            gr.Slider(
                minimum=0,
                maximum=1,
                step=0.1,
                value=0.95,
                label="Temperature",
                render=False,
            ),
            gr.Slider(
                minimum=128,
                maximum=4096,
                step=1,
                value=512,
                label="Max new tokens",
                render=False,
            ),
        ],
        examples=[
            ["HTMLã®ã‚µãƒ³ãƒ—ãƒ«ã‚’ä½œæˆã—ã¦"],
            [
                "CUDA_VISIBLE_DEVICES=0 llamafactory-cli train examples/lora_single_gpu/llama3_lora_sft.yaml"
            ],
        ],
        cache_examples=False,
    )

    gr.Markdown(LICENSE)
